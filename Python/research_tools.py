"""Research Tools.

This module provides search and content processing utilities for the research agent,
including web search capabilities and content summarization tools.

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è:
- –≤–µ–±-–ø–æ–∏—Å–∫–∞ (—á–µ—Ä–µ–∑ Tavily),
- –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü,
- —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª—ã (–¥–ª—è offloading –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞).

–û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º –∞–≥–µ–Ω—Ç–æ–º (research agent) –≤ Deep Agents.
"""
import os
from dotenv import load_dotenv
from datetime import datetime
import uuid, base64  # uuid –∏ base64 –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–º—ë–Ω —Ñ–∞–π–ª–æ–≤

import httpx
# from langchain.chat_models import init_chat_model
from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage, ToolMessage
from langchain_core.tools import InjectedToolArg, InjectedToolCallId, tool
from langgraph.prebuilt import InjectedState
from langgraph.types import Command
from markdownify import markdownify  # –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è HTML ‚Üí Markdown
from pydantic import BaseModel, Field
from tavily import TavilyClient
from typing_extensions import Annotated, Literal

# from deep_agents_from_scratch.prompts import SUMMARIZE_WEB_SEARCH
from prompts import SUMMARIZE_WEB_SEARCH
# from deep_agents_from_scratch.state import DeepAgentState
from state import DeepAgentState

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–∞ .env
load_dotenv()

# –°—á–∏—Ç—ã–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è, –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–ª—è LangSmith/LangChain
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
LANGSMITH_API_KEY = os.getenv("LANGSMITH_API_KEY")
LANGSMITH_TRACING = os.getenv("LANGSMITH_TRACING")
LANGSMITH_PROJECT = os.getenv("LANGSMITH_PROJECT")
LLM = os.getenv("LLM")

# ---------------------------------------------------------------------------
# üß† –ú–û–î–ï–õ–¨ –î–õ–Ø –°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–ò
# ---------------------------------------------------------------------------
# –û—Ç–¥–µ–ª—å–Ω–∞—è LLM-–º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π
# —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü. –ó–¥–µ—Å—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è openai:gpt-4o-mini
# —á–µ—Ä–µ–∑ init_chat_model (LangChain).
# summarization_model = init_chat_model(model="openai:gpt-4o-mini")
summarization_model = ChatOllama(
    model=LLM,
    # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ:
    # num_ctx=8192,
    # temperature=0.2,
)

# –ö–ª–∏–µ–Ω—Ç Tavily ‚Äî –≤–Ω–µ—à–Ω–∏–π API –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –≤–µ–±-–ø–æ–∏—Å–∫–∞
tavily_client = TavilyClient()


class Summary(BaseModel):
    """Schema for webpage content summarization.

    Pydantic-–º–æ–¥–µ–ª—å, –æ–ø–∏—Å—ã–≤–∞—é—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä–∞.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å with_structured_output, —á—Ç–æ–±—ã LLM –≤–æ–∑–≤—Ä–∞—â–∞–ª–∞
    —Å—Ç—Ä–æ–≥–æ –∑–∞–¥–∞–Ω–Ω—ã–π JSON-—Ñ–æ—Ä–º–∞—Ç: –∏–º—è —Ñ–∞–π–ª–∞ + –∫—Ä–∞—Ç–∫–æ–µ summary.
    """
    filename: str = Field(description="Name of the file to store.")
    summary: str = Field(description="Key learnings from the webpage.")


# def get_today_str() -> str:
#     """Get current date in a human-readable format.
#
#     –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –≤ —É–¥–æ–±–æ—á–∏—Ç–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –∫–æ—Ç–æ—Ä—ã–π
#     –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –≤ –ø—Ä–æ–º–ø—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏).
#     """
#     return datetime.now().strftime("%a %b %-d, %Y")
from datetime import datetime
def get_today_str() -> str:
    """Get current date in a human-readable, cross-platform format."""
    # "%a %b %d, %Y" –¥–∞—ë—Ç, –Ω–∞–ø—Ä–∏–º–µ—Ä: "Mon Dec 01, 2025"
    # –î–∞–ª–µ–µ —É–±–∏—Ä–∞–µ–º –≤–µ–¥—É—â–∏–π –Ω–æ–ª—å —É –¥–Ω—è –º–µ—Å—è—Ü–∞
    raw = datetime.now().strftime("%a %b %d, %Y")
    # "Dec 01" -> "Dec 1"
    return raw.replace(" 0", " ")

def run_tavily_search(
    search_query: str, 
    max_results: int = 1, 
    topic: Literal["general", "news", "finance"] = "general", 
    include_raw_content: bool = True, 
) -> dict:
    """Perform search using Tavily API for a single query.

    –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –∫ Tavily API.

    Args:
        search_query: –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        max_results: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        topic: —Ç–µ–º–∞ (–æ–±—â–∏–π, –Ω–æ–≤–æ—Å—Ç–∏, —Ñ–∏–Ω–∞–Ω—Å—ã)
        include_raw_content: –≤–∫–ª—é—á–∞—Ç—å –ª–∏ —Å—ã—Ä–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Tavily (JSON ‚Üí dict).
    """
    result = tavily_client.search(
        search_query,
        max_results=max_results,
        include_raw_content=include_raw_content,
        topic=topic
    )

    return result


def summarize_webpage_content(webpage_content: str) -> Summary:
    """Summarize webpage content using the configured summarization model.

    –°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π LLM-–º–æ–¥–µ–ª–∏
    –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Summary.

    Args:
        webpage_content: —Å—ã—Ä–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–æ–±—ã—á–Ω–æ markdown)

    Returns:
        –û–±—ä–µ–∫—Ç Summary —Å filename –∏ summary.
    """
    try:
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥ —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ö–µ–º–µ Summary
        structured_model = summarization_model.with_structured_output(Summary)

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç: –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –¥–∞—Ç—É –≤ —à–∞–±–ª–æ–Ω
        summary_and_filename = structured_model.invoke([
            HumanMessage(content=SUMMARIZE_WEB_SEARCH.format(
                webpage_content=webpage_content, 
                date=get_today_str()
            ))
        ])

        # –ú–æ–¥–µ–ª—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç Summary (filename + summary)
        return summary_and_filename

    except Exception:
        # –ù–∞ —Å–ª—É—á–∞–π –ª—é–±–æ–π –æ—à–∏–±–∫–∏ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–ø–∞—Å–Ω–æ–π Summary,
        # –≥–¥–µ summary = –ø–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞ (–∏–ª–∏ –≤—Å—ë, –µ—Å–ª–∏ –∫–æ—Ä–æ—á–µ)
        return Summary(
            filename="search_result.md",
            summary=webpage_content[:1000] + "..." if len(webpage_content) > 1000 else webpage_content
        )


def process_search_results(results: dict) -> list[dict]:
    """Process search results by summarizing content where available.

    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã Tavily-–ø–æ–∏—Å–∫–∞:
    - –ø—ã—Ç–∞–µ—Ç—Å—è —Å–∫–∞—á–∞—Ç—å HTML –ø–æ URL,
    - –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç HTML ‚Üí markdown,
    - —Å—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ,
    - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞,
    - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.

    Args:
        results: —Å–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ–∏—Å–∫–∞ Tavily

    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π: url, title, summary, filename, raw_content.
    """
    processed_results = []

    # –û—Ç–¥–µ–ª—å–Ω—ã–π HTTP-–∫–ª–∏–µ–Ω—Ç —Å —Ç–∞–π–º–∞—É—Ç–æ–º ‚Äî —á—Ç–æ–±—ã –Ω–µ –∑–∞–≤–∏—Å–Ω—É—Ç—å –Ω–∞ –¥–æ–ª–≥–∏—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö
    HTTPX_CLIENT = httpx.Client(timeout=30.0)  # —Ç–∞–π–º–∞—É—Ç 30 —Å–µ–∫—É–Ω–¥

    # –ò—Ç–µ—Ä–∏—Ä—É–µ–º—Å—è –ø–æ —Å–ø–∏—Å–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Tavily
    for result in results.get('results', []):

        # –ò–∑–≤–ª–µ–∫–∞–µ–º URL
        url = result['url']

        # –ü—ã—Ç–∞–µ–º—Å—è —Å—á–∏—Ç–∞—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ URL
        try:
            response = HTTPX_CLIENT.get(url)

            if response.status_code == 200:
                # –ï—Å–ª–∏ –≤—Å—ë –æ–∫ ‚Äî –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º HTML ‚Üí markdown
                raw_content = markdownify(response.text)
                # –°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ–º markdown-—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
                summary_obj = summarize_webpage_content(raw_content)
            else:
                # –ï—Å–ª–∏ –∫–æ–¥ –æ—Ç–≤–µ—Ç–∞ –Ω–µ 200 ‚Äî fallback:
                # –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—ã—Ä–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ/summary –æ—Ç Tavily
                raw_content = result.get('raw_content', '')
                summary_obj = Summary(
                    filename="URL_error.md",
                    summary=result.get('content', 'Error reading URL; try another search.')
                )
        except (httpx.TimeoutException, httpx.RequestError) as e:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è/—Ç–∞–π–º–∞—É—Ç–∞ ‚Äî –Ω–µ –ª–æ–º–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω,
            # –∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º Tavily content
            raw_content = result.get('raw_content', '')
            summary_obj = Summary(
                filename="connection_error.md",
                summary=result.get('content', f'Could not fetch URL (timeout/connection error). Try another search.')
            )

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Å—É—Ñ—Ñ–∏–∫—Å –¥–ª—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (—á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –∫–æ–ª–ª–∏–∑–∏–π)
        uid = base64.urlsafe_b64encode(uuid.uuid4().bytes).rstrip(b"=").decode("ascii")[:8]
        name, ext = os.path.splitext(summary_obj.filename)
        summary_obj.filename = f"{name}_{uid}{ext}"

        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        processed_results.append({
            'url': result['url'],
            'title': result['title'],
            'summary': summary_obj.summary,
            'filename': summary_obj.filename,
            'raw_content': raw_content,
        })

    return processed_results


@tool(parse_docstring=True)
def tavily_search(
    query: str,
    state: Annotated[DeepAgentState, InjectedState],
    tool_call_id: Annotated[str, InjectedToolCallId],
    max_results: Annotated[int, InjectedToolArg] = 1,
    topic: Annotated[Literal["general", "news", "finance"], InjectedToolArg] = "general",
) -> Command:
    """Search web and save detailed results to files while returning minimal context.

    –í—ã–ø–æ–ª–Ω—è–µ—Ç –≤–µ–±-–ø–æ–∏—Å–∫ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã
    (–¥–ª—è offloading –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞). –í –∫–æ–Ω—Ç–µ–∫—Å—Ç (messages) –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –∫—Ä–∞—Ç–∫—É—é
    —Å–≤–æ–¥–∫—É: –∫–∞–∫–∏–µ —Ñ–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã –∏ —á—Ç–æ –≤ –Ω–∏—Ö –≤ —Ü–µ–ª–æ–º —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è.

    Args:
        query: –ø–æ–∏—Å–∫–æ–≤–æ–π –∑–∞–ø—Ä–æ—Å
        state: —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ (InjectedState), –Ω—É–∂–Ω–æ –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ files
        tool_call_id: –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≤—ã–∑–æ–≤–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ (–¥–ª—è ToolMessage)
        max_results: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        topic: —Ç–∏–ø –ø–æ–∏—Å–∫–∞ ('general' | 'news' | 'finance')

    Returns:
        Command, –∫–æ—Ç–æ—Ä—ã–π:
        - –æ–±–Ω–æ–≤–ª—è–µ—Ç files (—Å–æ–∑–¥–∞—ë—Ç —Ñ–∞–π–ª—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ–∏—Å–∫–∞),
        - –¥–æ–±–∞–≤–ª—è–µ—Ç ToolMessage —Å –∫—Ä–∞—Ç–∫–∏–º summary.
    """
    # 1. –í—ã–ø–æ–ª–Ω—è–µ–º Tavily-–ø–æ–∏—Å–∫
    search_results = run_tavily_search(
        query,
        max_results=max_results,
        topic=topic,
        include_raw_content=True,
    ) 

    # 2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏ —Å—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    processed_results = process_search_results(search_results)

    # 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π —Ñ–∞–π–ª–æ–≤ –∏ –∫—Ä–∞—Ç–∫–æ–π —Å–≤–æ–¥–∫–∏
    files = state.get("files", {})
    saved_files = []
    summaries = []

    for i, result in enumerate(processed_results):
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞, –≤–æ–∑–≤—Ä–∞—â—ë–Ω–Ω–æ–µ —Å—É–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä–æ–º
        filename = result['filename']

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞:
        # - –∑–∞–≥–æ–ª–æ–≤–æ–∫
        # - URL
        # - –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        # - –¥–∞—Ç–∞
        # - –∫—Ä–∞—Ç–∫–æ–µ summary
        # - —Å—ã—Ä–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ (markdown)
        file_content = f"""# Search Result: {result['title']}

**URL:** {result['url']}
**Query:** {query}
**Date:** {get_today_str()}

## Summary
{result['summary']}

## Raw Content
{result['raw_content'] if result['raw_content'] else 'No raw content available'}
"""

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≤–∏—Ä—Ç—É–∞–ª—å–Ω—É—é —Ñ–∞–π–ª–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É (state["files"])
        files[filename] = file_content
        saved_files.append(filename)
        # –î–ª—è –∫—Ä–∞—Ç–∫–æ–π —Å–≤–æ–¥–∫–∏ –¥–æ–±–∞–≤–ª—è–µ–º –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –ø–æ –∫–∞–∂–¥–æ–º—É —Ñ–∞–π–ª—É
        summaries.append(f"- {filename}: {result['summary']}...")

    # 4. –ö—Ä–∞—Ç–∫–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ summary –¥–ª—è ToolMessage ‚Äî —á—Ç–æ–±—ã –∞–≥–µ–Ω—Ç –ø–æ–Ω–∏–º–∞–ª:
    # - —Å–∫–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞–π–¥–µ–Ω–æ,
    # - –∫–∞–∫ –æ–Ω–∏ –ø—Ä–∏–º–µ—Ä–Ω–æ –≤—ã–≥–ª—è–¥—è—Ç,
    # - –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ —á–∏—Ç–∞—Ç—å —á–µ—Ä–µ–∑ read_file().
    summary_text = f"""üîç Found {len(processed_results)} result(s) for '{query}':

{chr(10).join(summaries)}

Files: {', '.join(saved_files)}
üí° Use read_file() to access full details when needed."""

    # 5. –í–æ–∑–≤—Ä–∞—â–∞–µ–º Command ‚Äî LangGraph –ø—Ä–∏–º–µ–Ω–∏—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫ state.
    return Command(
        update={
            "files": files,
            "messages": [
                ToolMessage(summary_text, tool_call_id=tool_call_id)
            ],
        }
    )


@tool(parse_docstring=True)
def think_tool(reflection: str) -> str:
    """Tool for strategic reflection on research progress and decision-making.

    –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–π —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.

    –ó–∞—á–µ–º –Ω—É–∂–µ–Ω:
    - —Å–æ–∑–¥–∞—Ç—å ¬´–ø–∞—É–∑—É –Ω–∞ –ø–æ–¥—É–º–∞—Ç—å¬ª –º–µ–∂–¥—É –≤—ã–∑–æ–≤–∞–º–∏ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤;
    - —è–≤–Ω–æ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å:
        * —á—Ç–æ —É–∂–µ –Ω–∞–π–¥–µ–Ω–æ,
        * —á–µ–≥–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç,
        * –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –¥–∞–Ω–Ω—ã—Ö,
        * —Å—Ç–æ–∏—Ç –ª–∏ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –ø–æ–∏—Å–∫ –∏–ª–∏ —É–∂–µ –æ—Ç–≤–µ—á–∞—Ç—å.

    Args:
        reflection: —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç–∞—è –º—ã—Å–ª—å –∞–≥–µ–Ω—Ç–∞ –æ —Ö–æ–¥–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è

    Returns:
        –°—Ç—Ä–æ–∫–∞-–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ, —á—Ç–æ —Ä–µ—Ñ–ª–µ–∫—Å–∏—è ¬´–∑–∞–ø–∏—Å–∞–Ω–∞¬ª.
        (–í–∞–∂–Ω–æ –¥–ª—è –ª–æ–≥–æ–≤ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è —á–µ–ª–æ–≤–µ–∫–æ–º, –∫–∞–∫ –º—ã—Å–ª–∏—Ç –∞–≥–µ–Ω—Ç.)
    """
    return f"Reflection recorded: {reflection}"
